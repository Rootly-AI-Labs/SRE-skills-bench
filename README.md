# LLM Evaluation at the Rootly AI Labs ⚗️

This repository centralizes model evaluation work at the Rootly AI Labs.

| Name | Venue | Category | Source |
| --- | --- | --- | -- | 
| Pull Requests with Bugs | ER @ NeurIPS 2025 | Reasoning, Coding | *Will be released soon* |
| Environment Free Coding Benchmark Suite (EFCB) | New In ML @ ICML 2025, KnowFM @ ACL 2025 | Code Understanding | [Rootly-AI-Labs/efcb](https://github.com/Rootly-AI-Labs/efcb) | 
| GitHub Multiple Choice Questions (GMCQ, part of EFCB) | New In ML @ ICML 2025, KnowFM @ ACL 2025 | Code Understanding | [Rootly-AI-Labs/GMCQ-benchmark](https://github.com/Rootly-AI-Labs/GMCQ-benchmark) | 
| Terraform SRE Suite | *TBA* | Site Reliability Engineering | *Will be released soon* | 
| Apache Logs | *TBA* | Site Reliability Engineering | [Rootly-AI-Labs/logs-dataset](https://github.com/Rootly-AI-Labs/logs-dataset) | 
